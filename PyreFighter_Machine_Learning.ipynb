{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyreFighter - Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDCIsiP-0QrF"
      },
      "source": [
        "# Importation des packages\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\r\n",
        "from category_encoders.target_encoder import TargetEncoder\r\n",
        "from category_encoders.count import CountEncoder\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "\r\n",
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH_ZVaeH0TFU"
      },
      "source": [
        "# Lecture du DataFrame\r\n",
        "df = pd.read_csv('Pyrefighter_cleaned_database.csv', sep = ';')\r\n",
        "\r\n",
        "# On conserve uniquement les données pour le 1er camion arrivé sur les lieux\r\n",
        "df = df[(df[\"PumpOrder\"] == 1)]\r\n",
        "\r\n",
        "# Variables non pertinentes à supprimer\r\n",
        "to_drop = ['IncidentNumber',\r\n",
        "           'CalYear',\r\n",
        "           'AddressQualifier',\r\n",
        "           'FirstPumpArriving_DeployedFromStation',\r\n",
        "           'PumpOrder']\r\n",
        "\r\n",
        "# Sélection des variables qualitatives\r\n",
        "categorical = ['PropertyCategory', 'IncGeo_BoroughName', 'IncidentStationGround',\r\n",
        "               'DeployedFromStation_Name', 'DeployedFromLocation','HourMobilised', 'WeekdayMobilised', 'MonthMobilised']\r\n",
        "\r\n",
        "# Retype des variables qualitatives\r\n",
        "df[categorical] = df[categorical].astype(str)\r\n",
        "\r\n",
        "# Sélection des 3 variables dont l'interaction est susceptible d'avoir un effet sur la variable cible\r\n",
        "# Ne sera pas utilisé pour les modèles de type arbre\r\n",
        "to_poly = ['HourMobilised', 'WeekdayMobilised', 'CityCenter']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7x4Riqh0WG0"
      },
      "source": [
        "# REGRESSION LINEAIRE - RECHERCHE DES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On sélection un échantillon de 10 000 lignes\r\n",
        "df_sample = df.sample(n = 10000, random_state = 42)\r\n",
        "\r\n",
        "# Pour chaque variable de categorial, on rassemble les catégories trop petites dans une catégorie 'Other'\r\n",
        "for col in categorical:\r\n",
        "    for value, valueCount in df_sample[col].value_counts().items():\r\n",
        "        if valueCount < 100:\r\n",
        "            df_sample[col] = df_sample[col].replace(value, 'Other')\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target_sample = df_sample['ResponseTimeMinute']\r\n",
        "data_sample = df_sample.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_sample, target_sample, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées\r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "selector = SelectKBest()   \r\n",
        "linreg = LinearRegression()\r\n",
        "\r\n",
        "linreg_pipe = Pipeline([('preprocesser', preprocesser),\r\n",
        "                        ('selection', selector),   \r\n",
        "                        ('model', linreg)])\r\n",
        "\r\n",
        "# Paramètres testés par le GridSearchCV\r\n",
        "param_grid = {\r\n",
        "    'model__fit_intercept' : [True, False],\r\n",
        "    'preprocesser__poly_features__poly__degree' : [2, 3],\r\n",
        "    'preprocesser__count_encode__min_group_size' : [10, 50, 100]\r\n",
        "}\r\n",
        "\r\n",
        "# Recherche des paramètres optimaux\r\n",
        "grid = GridSearchCV(estimator = linreg_pipe, param_grid = param_grid, cv = 5, iid = True, n_jobs=-1)\r\n",
        "\r\n",
        "grid.fit(X_train,y_train)  \r\n",
        "\r\n",
        "print('Les meilleurs paramètres trouvés sont :', grid.best_params_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmQsSRS0W1j"
      },
      "source": [
        "# REGRESSION LINEAIRE - EXECUTION DU MODELE AVEC LES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On mesure le temps d'exécution du modèle\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target = df['ResponseTimeMinute']\r\n",
        "data = df.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées       \r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(degree = 2,\r\n",
        "                                                              include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "# Pamarètre optimaux sélectionnés\r\n",
        "params = {'fit_intercept': False}\r\n",
        "linreg = LinearRegression(**params)\r\n",
        "\r\n",
        "linreg_pipe = Pipeline([('preprocesser', preprocesser),   \r\n",
        "                        ('model', linreg)])\r\n",
        "\r\n",
        "linreg_pipe.fit(X_train,y_train)  \r\n",
        "y_pred = linreg_pipe.predict(X_test)\r\n",
        "ResponseTimeMinute_mean = df['ResponseTimeMinute'].mean()\r\n",
        "\r\n",
        "print('Score MSE train :', mean_squared_error(y_train, linreg_pipe.predict(X_train)))\r\n",
        "print('Score MAE train (en minute) :', mean_absolute_error(y_train, linreg_pipe.predict(X_train)))\r\n",
        "print('Score MSE test', mean_squared_error(y_test, linreg_pipe.predict(X_test)))\r\n",
        "print('Score MAE test (en minute)', mean_absolute_error(y_test, linreg_pipe.predict(X_test)))\r\n",
        "print(\"\\nRelative test error:\", mean_absolute_error(y_test, linreg_pipe.predict(X_test))/ResponseTimeMinute_mean)\r\n",
        "\r\n",
        "t1 = time() - t0\r\n",
        "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LjA9T250Y3q"
      },
      "source": [
        "# RIDGE REGRESSOR - RECHERCHE DES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On sélection un échantillon de 10 000 lignes\r\n",
        "df_sample = df.sample(n = 10000, random_state = 42)\r\n",
        "\r\n",
        "# Pour chaque variable de categorial, on rassemble les catégories trop petites dans une catégorie 'Other'\r\n",
        "for col in categorical:\r\n",
        "    for value, valueCount in df_sample[col].value_counts().items():\r\n",
        "        if valueCount < 100:\r\n",
        "            df_sample[col] = df_sample[col].replace(value, 'Other')\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target_sample = df_sample['ResponseTimeMinute']\r\n",
        "data_sample = df_sample.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_sample, target_sample, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées\r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(degree = 2,\r\n",
        "                                                              include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "ridge_reg = Ridge(random_state = 42)\r\n",
        "\r\n",
        "ridge_reg_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', ridge_reg)])   \r\n",
        "\r\n",
        "# Paramètres testés par le GridSearchCV\r\n",
        "param_grid = {\r\n",
        "    'preprocesser__poly_features__poly__degree' : [2, 3],\r\n",
        "    'preprocesser__count_encode__min_group_size' : [10, 50, 100],\r\n",
        "    'model__alpha': [float(x) for x in np.linspace(start = 0.000001, stop = 10, num = 10)]\r\n",
        "}\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator = ridge_reg_pipe, param_grid = param_grid, cv = 5, iid = True, n_jobs=-1)\r\n",
        "\r\n",
        "grid.fit(X_train, y_train)\r\n",
        "print('Les meilleurs paramètres trouvés sont :', grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bqh1Azn0aht"
      },
      "source": [
        "# RIDGE REGRESSOR - EXECUTION DU MODELE AVEC LES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On mesure le temps d'exécution du modèle\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "target = df['ResponseTimeMinute']\r\n",
        "data = df.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées\r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(degree = 2,\r\n",
        "                                                              include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "# Pamarètre optimaux sélectionnés\r\n",
        "params = {'alpha': 10.0, 'random_state':  42}\r\n",
        "ridge_reg = Ridge(**params)\r\n",
        "\r\n",
        "ridge_reg_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', ridge_reg)])   \r\n",
        "\r\n",
        "ridge_reg_pipe.fit(X_train, y_train)\r\n",
        "ResponseTimeMinute_mean = df['ResponseTimeMinute'].mean()\r\n",
        "\r\n",
        "print('Score MSE train :', mean_squared_error(y_train, ridge_reg_pipe.predict(X_train)))\r\n",
        "print('Score MAE train (en minute) :', mean_absolute_error(y_train, ridge_reg_pipe.predict(X_train)))\r\n",
        "print('Score MSE test', mean_squared_error(y_test, ridge_reg_pipe.predict(X_test)))\r\n",
        "print('Score MAE test (en minute)', mean_absolute_error(y_test, ridge_reg_pipe.predict(X_test)))\r\n",
        "print(\"\\nRelative test error:\", mean_absolute_error(y_test, ridge_reg_pipe.predict(X_test))/ResponseTimeMinute_mean)\r\n",
        "\r\n",
        "t1 = time() - t0\r\n",
        "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36r9V0qs0cjM"
      },
      "source": [
        "# LASSO REGRESSOR - RECHERCHE DES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On sélection un échantillon de 10 000 lignes\r\n",
        "df_sample = df.sample(n = 10000, random_state = 42)\r\n",
        "\r\n",
        "# Pour chaque variable de categorial, on rassemble les catégories trop petites dans une catégorie 'Other'\r\n",
        "for col in categorical:\r\n",
        "    for value, valueCount in df_sample[col].value_counts().items():\r\n",
        "        if valueCount < 100:\r\n",
        "            df_sample[col] = df_sample[col].replace(value, 'Other')\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target_sample = df_sample['ResponseTimeMinute']\r\n",
        "data_sample = df_sample.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_sample, target_sample, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées\r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(degree = 2,\r\n",
        "                                                              include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "lasso_reg = Lasso(random_state = 42)\r\n",
        "\r\n",
        "lasso_reg_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', lasso_reg)])   \r\n",
        "\r\n",
        "# Paramètres testés par le GridSearchCV\r\n",
        "param_grid = {\r\n",
        "    'preprocesser__poly_features__poly__degree' : [2, 3],\r\n",
        "    'preprocesser__count_encode__min_group_size' : [10, 50, 100],\r\n",
        "    'model__alpha': [float(x) for x in np.linspace(start = 0.000001, stop = 10, num = 10)]\r\n",
        "}\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator = lasso_reg_pipe, param_grid = param_grid, cv = 5, iid = True, n_jobs=-1)\r\n",
        "\r\n",
        "grid.fit(X_train, y_train)\r\n",
        "print('Les meilleurs paramètres trouvés sont :', grid.best_params_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYhAHJX0eWf"
      },
      "source": [
        "# LASSO REGRESSOR - EXECUTION DU MODELE AVEC LES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On mesure le temps d'exécution du modèle\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target = df['ResponseTimeMinute']\r\n",
        "data = df.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Pipeline de test d'interaction des 3 variables sélectionnées\r\n",
        "poly_features = Pipeline(steps = [(\"ohe\", OneHotEncoder()),\r\n",
        "    \r\n",
        "                                  (\"poly\", PolynomialFeatures(degree = 2,\r\n",
        "                                                              include_bias = False,\r\n",
        "                                                              interaction_only = True)),\r\n",
        "                                  (\"target\", TargetEncoder())])\r\n",
        "\r\n",
        "# Suppression des variables inutiles, application de la méthode PolynomialFeatures et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"poly_features\", poly_features, to_poly),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "# Pamarètre optimaux sélectionnés\r\n",
        "params = {'alpha': 1e-06, 'random_state':  42}\r\n",
        "lasso_reg = Lasso(**params)\r\n",
        "\r\n",
        "lasso_reg_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', lasso_reg)])   \r\n",
        "\r\n",
        "lasso_reg_pipe.fit(X_train, y_train)\r\n",
        "ResponseTimeMinute_mean = df['ResponseTimeMinute'].mean()\r\n",
        "\r\n",
        "print('Score MSE train :', mean_squared_error(y_train, lasso_reg_pipe.predict(X_train)))\r\n",
        "print('Score MAE train (en minute) :', mean_absolute_error(y_train, lasso_reg_pipe.predict(X_train)))\r\n",
        "print('Score MSE test', mean_squared_error(y_test, lasso_reg_pipe.predict(X_test)))\r\n",
        "print('Score MAE test (en minute)', mean_absolute_error(y_test, lasso_reg_pipe.predict(X_test)))\r\n",
        "print(\"\\nRelative test error:\", mean_absolute_error(y_test, lasso_reg_pipe.predict(X_test))/ResponseTimeMinute_mean)\r\n",
        "\r\n",
        "t1 = time() - t0\r\n",
        "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA_4f3gv0gCm"
      },
      "source": [
        "# GRADIENT BOOSTING REGRESSOR - RECHERCHE DES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On sélection un échantillon de 10 000 lignes\r\n",
        "df_sample = df.sample(n = 10000, random_state = 42)\r\n",
        "\r\n",
        "# Pour chaque variable de categorial, on rassemble les catégories trop petites dans une catégorie 'Other'\r\n",
        "for col in categorical:\r\n",
        "    for value, valueCount in df_sample[col].value_counts().items():\r\n",
        "        if valueCount < 100:\r\n",
        "            df_sample[col] = df_sample[col].replace(value, 'Other')\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target_sample = df_sample['ResponseTimeMinute']\r\n",
        "data_sample = df_sample.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_sample, target_sample, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Suppression des variables inutiles et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "gbr = GradientBoostingRegressor(random_state = 42)\r\n",
        "\r\n",
        "gbr_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', gbr)])   \r\n",
        "\r\n",
        "# Paramètres testés par le GridSearchCV\r\n",
        "param_grid = {\r\n",
        "    'preprocesser__count_encode__min_group_size' : [10, 50, 100],\r\n",
        "    'model__n_estimators': [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)],\r\n",
        "    'model__max_features': ['auto'],\r\n",
        "    'model__max_depth': [int(x) for x in np.linspace(0, 100, num = 10)],\r\n",
        "    'model__min_samples_split': [1, 10, 100]\r\n",
        "}\r\n",
        "\r\n",
        "grid = GridSearchCV(estimator = gbr_pipe, param_grid = param_grid, cv = 5, iid = True, n_jobs=-1)\r\n",
        "grid.fit(X_train, y_train)\r\n",
        "\r\n",
        "print('Les meilleurs paramètres trouvés sont :', grid.best_params_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsF9hDgr0h1d"
      },
      "source": [
        "# GRADIENT BOOSTING REGRESSOR - EXECUTION DU MODELE AVEC LES PARAMETRES OPTIMAUX\r\n",
        "\r\n",
        "# On mesure le temps d'exécution du modèle\r\n",
        "t0 = time()\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target = df['ResponseTimeMinute']\r\n",
        "data = df.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Suppression des variables inutiles et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "# Pamarètre optimaux sélectionnés\r\n",
        "params = {'max_depth': 11, 'max_features': 'auto', 'min_samples_split': 100, 'n_estimators': 10, 'random_state': 42}\r\n",
        "\r\n",
        "gbr = GradientBoostingRegressor(**params)\r\n",
        "\r\n",
        "gbr_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', gbr)])   \r\n",
        "\r\n",
        "gbr_pipe.fit(X_train, y_train)\r\n",
        "ResponseTimeMinute_mean = df['ResponseTimeMinute'].mean()\r\n",
        "\r\n",
        "print('Score MSE train :', mean_squared_error(y_train, gbr_pipe.predict(X_train)))\r\n",
        "print('Score MAE train (en minute) :', mean_absolute_error(y_train, gbr_pipe.predict(X_train)))\r\n",
        "print('Score MSE test', mean_squared_error(y_test, gbr_pipe.predict(X_test)))\r\n",
        "print('Score MAE test (en minute)', mean_absolute_error(y_test, gbr_pipe.predict(X_test)))\r\n",
        "print(\"\\nRelative test error:\", mean_absolute_error(y_test, gbr_pipe.predict(X_test))/ResponseTimeMinute_mean)\r\n",
        "t1 = time() - t0\r\n",
        "print(\"Réalisé en {} secondes\".format(round(t1,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1NtospV6fx6"
      },
      "source": [
        "# Visualisation du modèle GRADIENT BOOSTING REGRESSOR\r\n",
        "\r\n",
        "# Séparation de le variable cible des variables explicatives\r\n",
        "target = df['ResponseTimeMinute']\r\n",
        "data = df.drop(['ResponseTimeMinute'], axis = 1)\r\n",
        "\r\n",
        "# Séparation du jeu de données en un ensemble d'entraînement et un ensemble test\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2, random_state = 1)\r\n",
        "\r\n",
        "# Suppression des variables inutiles et encodage des variables qualitatives\r\n",
        "preprocesser = ColumnTransformer(transformers = [(\"drop_columns\", 'drop', to_drop),\r\n",
        "                                                 (\"target_encode\", TargetEncoder(), categorical),\r\n",
        "                                                 (\"count_encode\", CountEncoder(min_group_size = 10), categorical)],\r\n",
        "                                 remainder = 'drop')\r\n",
        "\r\n",
        "# Pamarètre optimaux sélectionnés\r\n",
        "params = {'max_depth': 11, 'max_features': 'auto', 'min_samples_split': 100, 'n_estimators': 10, 'random_state': 42}\r\n",
        "\r\n",
        "gbr = GradientBoostingRegressor(**params)\r\n",
        "\r\n",
        "gbr_pipe = Pipeline([('preprocesser', preprocesser),          \r\n",
        "                     ('model', gbr)])   \r\n",
        "\r\n",
        "gbr_pipe.fit(X_train, y_train)\r\n",
        "\r\n",
        "y_pred_test = gbr_pipe.predict(X_test)\r\n",
        "\r\n",
        "# On assemble nos données X_test et Y_test dans un DataFrame\r\n",
        "df_y_pred_test = pd.DataFrame(y_pred_test)\r\n",
        "df_ML = X_test.assign(ResponseTimeMinute = df_y_pred_test.values)\r\n",
        "\r\n",
        "# On sélectionne 5 incidents\r\n",
        "df_viz_pred = df_ML[(df_ML[\"IncidentNumber\"] == \"169070-18122017\") | (df_ML[\"IncidentNumber\"] == \"010154-24012020\") | (df_ML[\"IncidentNumber\"] == \"087083-16072020\") | (df_ML[\"IncidentNumber\"] == \"066277-26052017\") | (df_ML[\"IncidentNumber\"] == \"062086-17052017\")]\r\n",
        "df_viz_reel = df[((df[\"IncidentNumber\"] == \"169070-18122017\") | (df[\"IncidentNumber\"] == \"010154-24012020\") | (df[\"IncidentNumber\"] == \"087083-16072020\") | (df[\"IncidentNumber\"] == \"066277-26052017\") | (df[\"IncidentNumber\"] == \"062086-17052017\"))]\r\n",
        "\r\n",
        "# On créé notre graphique\r\n",
        "barWidth = 0.4\r\n",
        "x1 = range(5)\r\n",
        "x2 = [r + barWidth for r in x1 ]\r\n",
        "\r\n",
        "plt.bar(x1, df_viz_reel['ResponseTimeMinute'], color = 'green', label = 'Réel', width = barWidth)\r\n",
        "plt.bar(x2, df_viz_pred['ResponseTimeMinute'], label = 'Prédit', width = barWidth)\r\n",
        "plt.title('Visualisation des temps de réponse réels et prédits')\r\n",
        "plt.ylabel('Temps de réponse (min)')\r\n",
        "plt.xlabel('Incidents')\r\n",
        "plt.legend();\r\n",
        "\r\n",
        "# Enregistrement de la figure\r\n",
        "fig = plt.gcf()\r\n",
        "fig.savefig(\"ModèleGBR.png\", dpi = 300, bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}